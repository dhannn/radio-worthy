{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Music is an important artifact of culture and society. Thus, analyzing song data can reveal a lot about the societal trends. Music consumption, specifically, tells us how society."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Dataset\n",
    "To aid in our investigation, we use [Dhruvil Dave's dataset](https://www.kaggle.com/datasets/dhruvildave/billboard-the-hot-100-songs/) on songs from the Billboard Hot 100, ranging from the year 1958 to 2021.\n",
    "\n",
    "All dataset and other intermediary data are stored in the `/data` folder in the root directory of this project. Let's move up a directory so that we have access to the data we're using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can load our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "charts_df = pd.read_csv('data/charts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring our variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have a DataFrame object we can work with! Let us explore the observations and variables in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charts_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 330 087 observations and six variables in our dataset. The variables and their description are as follows:\n",
    "- **date**: date of the chart\n",
    "- **rank**: rank of the song\n",
    "- **song**: song title\n",
    "- **artist**: artist name\n",
    "- **last-week**: rank of the song in the preceding week\n",
    "- **peak-rank**: the highest rank that the song historically charted\n",
    "- **weeks-on-board**: how many weeks the song is charting up to the point of the record (does not have to be consecutive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `date`, `song` and `artist` variables are object types (or string types) while the rest are numeric types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charts_df['date'] = pd.to_datetime(charts_df['date'])\n",
    "charts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling null and duplicate variables\n",
    "Out of all the variables, the `last-week` variable contains some non-null values as seen in the output for `charts_df.info()`. We can see below how many actual null values we have (32 312 rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charts_df['last-week'][charts_df['last-week'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is expected, however. These null values simply mean that the song entry is new to the charts which corresponds to no record for last week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For duplicates, the variables `date`, `rank` and other similar chart variables are expected to duplicate. Artists may also have multiple charting songs throughout their career. Songs may chart multiple weeks as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, for the sake of analysis, we might need to create a single entry for each song instead and extract the most relevant features: the `peak-rank` and the maximum value for `weeks-on-board` of that song. \n",
    "\n",
    "In this way, we trim our dataset and remove extraneous fluff that may hinder our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But before we remove the duplicates, we must consider engineering more features. I will explain in a while why we must do feature engineering before handling duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering\n",
    "Since we're working with dataset that pertains to cultural trends, one interesting feature we might explore is the decade. We can bin these dates to certain years and decades of the charting.\n",
    "\n",
    "Here we extract the year of the charting period of a given entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_series = charts_df['date'].dt.year.apply(lambda x: int(x))\n",
    "year_series.name = 'year'\n",
    "year_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the analysis to be more helpful, it could benefit from putting the years to specific bins of decades as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decade_series = (year_series // 10 * 10).apply(lambda x: int(x))\n",
    "decade_series.name = 'decade'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then concatenate the series of new features to our cleaned `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_charts_df = pd.concat([charts_df, year_series, decade_series], axis='columns')\n",
    "cleaned_charts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The years in the decades 2020s and 1950s are not of standard length since the dataset only involves the one or two years in that decades. To extract useful comparison between each decade, we can limit our range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_charts_df = cleaned_charts_df.query('decade < 2020 & decade > 1950')\n",
    "cleaned_charts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember we have duplicate entries for each time a particular song enters the charts. However, it might be useful to have the most important \"summary\" of the song. This would be the max peak (highest peak throughout the song's lifetime in the charts) and the total weeks on board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_running_charting = cleaned_charts_df.groupby(['song', 'artist', 'decade'], as_index=False).aggregate('max')[['song', 'artist', 'decade', 'weeks-on-board']]\n",
    "top_rank = cleaned_charts_df.groupby(['song', 'artist', 'decade'], as_index=False).aggregate('min')['rank']\n",
    "cleaned_charts_df = pd.concat([longest_running_charting, top_rank], axis='columns')\n",
    "cleaned_charts_df.sort_values(axis='rows', by='decade')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the chart data alone might not have the most groundbreaking insights. We can augment this primary dataset with another to broaden our investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df = pd.read_csv('data/tracks.csv')\n",
    "tracks_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Yamac Eren's dataset](https://www.kaggle.com/datasets/yamaerenay/spotify-dataset-19212020-600k-tracks) consists of Spotify data of around 600 000 tracks. Like the Billboard Hot 100, this dataset can be generated from public data given by Spotify. Specifically, it can be gathered through the Spotify API.\n",
    "\n",
    "It consists of the following important features: \n",
    "- **name**: the title of the song\n",
    "- **duration_ms**: the length of the song in millisecond\n",
    "- **artists**: an array of artists featured in the song\n",
    "- **danceability**: \"how suitable a track is for dancing based on a combination of musical elements\"\n",
    "- **energy**: \"represents a perceptual measure of intensity and activity\"\n",
    "- **loudness**: \"overall loudness of a track in decibels\"\n",
    "- **acousticness**: \"confidence measure from 0.0 to 1.0 of whether the track is acoustic\"\n",
    "- **valence**: \"describing the musical positiveness conveyed by a track\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To cross-reference the songs from the charts to the Spotify data, we need the title and the artist to match. \n",
    "\n",
    "However, since the artists is in a string format resembling an array, we need to \"evaluate\" it and get the first artist to match it with the charts `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df['artist'] = tracks_df['artists'].apply(lambda x: eval(x)[0])\n",
    "tracks_df['artist']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This methodology, however, might have some consequences that we might consider when we interpret our data in the succeeding notebooks. Some artist fields in the original dataset have artist features in them (more than one artists on the same track). \n",
    "\n",
    "Since we're only matching one artist in the Spotify data, we might not be able to merge them all. One way to address this is to separate the artists within a track. In other words, for every token that resembles more than one artist, we duplicate the entry with each artist on one record. In this way, we can properly match all songs in the first `DataFrame` to the second.\n",
    "\n",
    "However, there are plenty ways to signify an artist feature (e.g. \"Featuring.\", \"Feat.\", \"&\", \",\", ...). In the interest of time, we ignore the songs with artist features. Since we have a large sample size, we can justify this action via central limit theorem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Another caveat in our augmented dataset is the duplicate tracks. Since Spotify tracks all versions of a track, the same song might have multiple records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df[tracks_df.duplicated(subset=['name', 'artists'], keep=False)].sort_values('name').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To address this, we just drop the duplicates since they more or less refer to the same song with similar features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df.drop_duplicates(subset=['name', 'artists'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine all these features together in a single `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = cleaned_charts_df.merge(tracks_df[['name', 'artist', 'duration_ms', 'danceability', 'energy', 'loudness','mode', 'speechiness', 'acousticness', 'instrumentalness', 'valence']], left_on=['song', 'artist'], right_on=['name', 'artist'])\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the same `DataFrame` in the future, we can simple serialize our object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_pickle('./data/pkls/charts_with_audio_features_df.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
